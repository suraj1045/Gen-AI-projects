{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d945acb4",
   "metadata": {},
   "source": [
    "### Implement a legal document question-answering and summarization system that retrieves relevant case law content using FAISS and generate multi-level summaries or answers using a language model like T5 or LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9d5f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Surest Way to Legal Research!™\\nUniting the authentic and reliable content from India’s leading law publisher with cutting-edge technology to create a powerful legal research resource.\\nNow available at your desk or on the move, spend less time researching, and have more time to focus on crafting your arguments.', \"-\\nAIROnline 2025 SC 905\\nSupreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran, Atul S. Chandurkar , JJ\\nSanjay D. Jain v. State of MaharashtraCRIMINAL APPEAL - 4292 of 2025 , (ARISING OUT OF SPECIAL LEAVE PETITION (CRL.) NO.12584 OF 2024), decided on 26/09/2025\\n-\\nAIROnline 2025 SC 899\\nSupreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran , J\\nRaghav Prashad v. State of U.P.CRIMINAL APPEAL - 596 of 2014 , decided on 26/09/2025\\n-\\nAIROnline 2025 SC 904\\nSupreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran , J\\nState of Telangana v. Jerusalem MathaiSpecial Leave Petition (Crl.) - 5248 of 2016 , With Special Leave Petition (Crl.) No.9333 of 2016, , decided on 26/09/2025\\n-\\nAIROnline 2025 SC 923\\nSupreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran, N. V. Anjaria , JJ\\nNew India Assurance Co. Ltd. v. Narayan SinghCIVIL APPEAL - 12279 of 2025 , SPECIAL LEAVE PETITION (C) NO. 19976 OF 2019,, decided on 26/09/2025\\nCriminal P.C. (2 of 1974) , S.482— Quashing of FIR - Prima facie case - Appellants accused persons were father-in-law, mother-in-law and sister-in-law of complainant - Allegations in FIR were regarding demand for furthe...Read More\\nPenal Code (45 of 1860) , S.302, S.304 Part 1— Murder or culpable homicide not amounting to murder - Intention to cause death - Allegation that accused persons had an altercation with complainant's father and uncles, ov...Read More\\nCriminal P.C. (2 of 1974) , S.482— Quashing of proceedings - Complainant MLA had alleged that accused offered him money and ticket to go abroad so as to abstain from voting or vote in a particular manner in upcoming MLC...Read More\\nMotor Vehicles Act (59 of 1988) , S.166— Accident claim - Grant of compensation - Challenge against - After award was passed by Tribunal, review application was filed by Insurer on ground that owner of offending vehicle...Read More\", '1 - 10 of 355132 (0.02 seconds)\\nUttar Haryana Bijli Vitran Nigam ... vs Central Electricity Regulatory ... on 7 April, 2016\\nFull Bench\\nSupreme Court of India. The arguments of learned senior counsel for\\ndefendant no.1 can be summarised as under:\\n(i) The Supreme Court of India ... Supreme Court of India, which is\\nevident from the fact that:\\n(a) in the application filed by the plaintiffs before the\\nSupreme Court of India\\nRavinder vs Govt. Of Nct Of Delhi & Ors. on 26 April, 2018\\nAuthor: S\\nWilfred J. Anr vs Moef Ors on 17 July, 2014\\nBEFORE THE NATIONAL GREEN TRIBUNAL\\nWilfred J. Anr vs Moef Ors on 17 July, 2014\\nBEFORE THE NATIONAL GREEN TRIBUNAL\\nM/S Shakuntla Educational And Welfare ... vs Yamuna Expressway Industrial ... on 10 July, 2024\\nAuthor\\nWP(C)/6446/2023 on 24 January, 2024\\nAuthor: Manish Choudhury\\nBench: Manish Choudhury\\nPage\\nSupreme Court was whether the alienation of plaint schedule IV, is open to challenge?\\n18. The Honble Supreme Court of India while considering ... appeal before the Honble Supreme Court of India.\\n21. The Honble Supreme Court of India in the said decision held that in order\\nMahesh Dnyandeo Waditake And Another vs The Union Of India And Others on 21 October\\nGangadhar Kundlik Narwade And Others vs The State Of Maharashtra And Others on 21 October']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#prepareing the data\n",
    "\n",
    "    # import requests\n",
    "    # from bs4 import BeautifulSoup\n",
    "import trafilatura \n",
    "urls = [\n",
    "    \"https://www.scconline.com/\",\n",
    "    \"https://nludelhi.ac.in/library/e-databases/\",\n",
    "    \"https://www.aironline.in/\",\n",
    "    \"https://indiankanoon.org/search/?formInput=document+of+Supreme+Court+of+India\"\n",
    "]\n",
    "all_text = []\n",
    "for url in urls:\n",
    "    download = trafilatura.fetch_url(url)\n",
    "    if download:\n",
    "        text = trafilatura.extract(download)\n",
    "        if text:\n",
    "            all_text.append(text)\n",
    "    # try:\n",
    "    #     html = requests.get(url).text\n",
    "    #     soup = BeautifulSoup(html, 'html.parser')\n",
    "    #     # Remove script and style elements\n",
    "    #     for script in soup([\"script\", \"style\"]):\n",
    "    #         script.decompose()\n",
    "\n",
    "    #     text = soup.get_text()\n",
    "    #     all_text.append(text)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Could not retrieve text from {url}: {e}\")\n",
    "\n",
    "print(all_text)\n",
    "print(len(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d49cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks: 6\n",
      "--- Chunk 1 ---\n",
      "The Surest Way to Legal Research!™\n",
      "Uniting the authentic and reliable content from India’s leading law publisher with cutting-edge technology to create a powerful legal research resource.\n",
      "Now available at your desk or on the move, spend less time researching, and have more time to focus on crafting your arguments.\n",
      "--- Chunk 2 ---\n",
      "-\n",
      "AIROnline 2025 SC 905\n",
      "Supreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran, Atul S. Chandurkar , JJ\n",
      "Sanjay D. Jain v. State of MaharashtraCRIMINAL APPEAL - 4292 of 2025 , (ARISING OUT OF SPECIAL LEAVE PETITION (CRL.) NO.12584 OF 2024), decided on 26/09/2025\n",
      "-\n",
      "AIROnline 2025 SC 899\n",
      "Supreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran , J\n",
      "Raghav Prashad v. State of U.P.CRIMINAL APPEAL - 596 of 2014 , decided on 26/09/2025\n",
      "-\n",
      "AIROnline 2025 SC 904\n",
      "Supreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran , J\n",
      "State of Telangana v. Jerusalem MathaiSpecial Leave Petition (Crl.) - 5248 of 2016 , With Special Leave Petition (Crl.) No.9333 of 2016, , decided on 26/09/2025\n",
      "-\n",
      "AIROnline 2025 SC 923\n",
      "Supreme Court Of IndiaHon'ble Judge(s): K. Vinod Chandran, N. V. Anjaria , JJ\n",
      "New India Assurance Co. Ltd. v. Narayan SinghCIVIL APPEAL - 12279 of 2025 , SPECIAL LEAVE PETITION (C) NO. 19976 OF 2019,, decided on 26/09/2025\n",
      "--- Chunk 3 ---\n",
      "New India Assurance Co. Ltd. v. Narayan SinghCIVIL APPEAL - 12279 of 2025 , SPECIAL LEAVE PETITION (C) NO. 19976 OF 2019,, decided on 26/09/2025\n",
      "Criminal P.C. (2 of 1974) , S.482— Quashing of FIR - Prima facie case - Appellants accused persons were father-in-law, mother-in-law and sister-in-law of complainant - Allegations in FIR were regarding demand for furthe...Read More\n",
      "Penal Code (45 of 1860) , S.302, S.304 Part 1— Murder or culpable homicide not amounting to murder - Intention to cause death - Allegation that accused persons had an altercation with complainant's father and uncles, ov...Read More\n",
      "Criminal P.C. (2 of 1974) , S.482— Quashing of proceedings - Complainant MLA had alleged that accused offered him money and ticket to go abroad so as to abstain from voting or vote in a particular manner in upcoming MLC...Read More\n",
      "--- Chunk 4 ---\n",
      "Motor Vehicles Act (59 of 1988) , S.166— Accident claim - Grant of compensation - Challenge against - After award was passed by Tribunal, review application was filed by Insurer on ground that owner of offending vehicle...Read More\n",
      "--- Chunk 5 ---\n",
      "1 - 10 of 355132 (0.02 seconds)\n",
      "Uttar Haryana Bijli Vitran Nigam ... vs Central Electricity Regulatory ... on 7 April, 2016\n",
      "Full Bench\n",
      "Supreme Court of India. The arguments of learned senior counsel for\n",
      "defendant no.1 can be summarised as under:\n",
      "(i) The Supreme Court of India ... Supreme Court of India, which is\n",
      "evident from the fact that:\n",
      "(a) in the application filed by the plaintiffs before the\n",
      "Supreme Court of India\n",
      "Ravinder vs Govt. Of Nct Of Delhi & Ors. on 26 April, 2018\n",
      "Author: S\n",
      "Wilfred J. Anr vs Moef Ors on 17 July, 2014\n",
      "BEFORE THE NATIONAL GREEN TRIBUNAL\n",
      "Wilfred J. Anr vs Moef Ors on 17 July, 2014\n",
      "BEFORE THE NATIONAL GREEN TRIBUNAL\n",
      "M/S Shakuntla Educational And Welfare ... vs Yamuna Expressway Industrial ... on 10 July, 2024\n",
      "Author\n",
      "WP(C)/6446/2023 on 24 January, 2024\n",
      "Author: Manish Choudhury\n",
      "Bench: Manish Choudhury\n",
      "Page\n",
      "Supreme Court was whether the alienation of plaint schedule IV, is open to challenge?\n",
      "--- Chunk 6 ---\n",
      "Author\n",
      "WP(C)/6446/2023 on 24 January, 2024\n",
      "Author: Manish Choudhury\n",
      "Bench: Manish Choudhury\n",
      "Page\n",
      "Supreme Court was whether the alienation of plaint schedule IV, is open to challenge?\n",
      "18. The Honble Supreme Court of India while considering ... appeal before the Honble Supreme Court of India.\n",
      "21. The Honble Supreme Court of India in the said decision held that in order\n",
      "Mahesh Dnyandeo Waditake And Another vs The Union Of India And Others on 21 October\n",
      "Gangadhar Kundlik Narwade And Others vs The State Of Maharashtra And Others on 21 October\n",
      "chunk size;\n"
     ]
    }
   ],
   "source": [
    "#chunking the data\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,  #number of charecters in each chunk\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "all_chunks = []\n",
    "for text in all_text:\n",
    "    chunks = splitter.split_text(text)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "print(\"number of chunks:\", len(all_chunks))\n",
    "for i, chunk in enumerate(all_chunks[:6]):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(chunk)\n",
    "print(\"chunk size;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175836b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/bq3dtrr94fg6sb9l307s0khr0000gp/T/ipykernel_86504/1545488527.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/Users/SRJ/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#conversion from chunks to vectors (embedding the chunks)\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_texts(all_chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebed6f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/var/folders/ss/bq3dtrr94fg6sb9l307s0khr0000gp/T/ipykernel_86504/4226310754.py:9: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipeline)\n",
      "/var/folders/ss/bq3dtrr94fg6sb9l307s0khr0000gp/T/ipykernel_86504/4226310754.py:19: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The Surest Way to Legal Research!TM Uniting the authentic and reliable content from India’s leading law publisher with cutting-edge technology to create a powerful legal research resource.\n"
     ]
    }
   ],
   "source": [
    "#loading the model (t5 model)\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "\n",
    "#create a retriver \n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "\n",
    "#connect the retriver with the model\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever = retriever)\n",
    "\n",
    "query = input(\"Enter your query: \")\n",
    "response = qa_chain.run(query)\n",
    "print(\"Response:\", response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21612e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LRScheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#conversion of text to vector\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfaiss\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/sentence_transformers/__init__.py:15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[32m      8\u001b[39m __all__ = [\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCrossEncoder\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCrossEncoderTrainer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCrossEncoderTrainingArguments\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCrossEncoderModelCardData\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/sentence_transformers/cross_encoder/trainer.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator, SequentialEvaluator\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerTrainer\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_datasets_available, is_training_available\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/sentence_transformers/trainer.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_collator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollator\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WandbCallback\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TRAINING_ARGS_NAME\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvalLoopOutput\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_collator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerDataCollator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/transformers/trainer.py:73\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, load_sharded_checkpoint, unwrap_model\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     70\u001b[39m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001b[32m     71\u001b[39m     MODEL_MAPPING_NAMES,\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adafactor, get_scheduler\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProcessorMixin\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     76\u001b[39m     is_torch_greater_or_equal_than_2_3,\n\u001b[32m     77\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/transformers/optimization.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LambdaLR, ReduceLROnPlateau\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer_pt_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerWiseDummyOptimizer, LayerWiseDummyScheduler\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SchedulerType\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/GenAI/.venvgenai/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:1364\u001b[39m\n\u001b[32m   1360\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure=\u001b[38;5;28;01mNone\u001b[39;00m) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m   1361\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1364\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLayerWiseDummyScheduler\u001b[39;00m(\u001b[43mLRScheduler\u001b[49m):\n\u001b[32m   1365\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1366\u001b[39m \u001b[33;03m    For Layer-wise optimizers such as GaLoRE optimizer, the optimization and scheduling step\u001b[39;00m\n\u001b[32m   1367\u001b[39m \u001b[33;03m    are already done through the post gradient hooks. Therefore\u001b[39;00m\n\u001b[32m   1368\u001b[39m \u001b[33;03m    the trick is to create a dummy scheduler that can take arbitrary\u001b[39;00m\n\u001b[32m   1369\u001b[39m \u001b[33;03m    args and kwargs and return a no-op during training.\u001b[39;00m\n\u001b[32m   1370\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n",
      "\u001b[31mNameError\u001b[39m: name 'LRScheduler' is not defined"
     ]
    }
   ],
   "source": [
    "#alternative method \n",
    "#conversion of text to vector using sentence transformer and faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_model = SentanceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedding_model.encode(all_chunks)\n",
    "vector_store = FAISS.from_texts(all_chunks, embeddings)\n",
    "\n",
    "#set up retriver for rag pipeline\n",
    "retriver = vector_store.as_retriever(search_type=\"similarity\", search_keyword=\"content\", search_kwargs={\"k\":3})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
